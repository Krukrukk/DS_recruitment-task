{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie rekrutascyjne - Data Scientist - 3Soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import json\n",
    "import yaml\n",
    "from utilities.utl_eval import eval_metrics, preperation_data\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "Napisz funkcję 'dt_pred', która w oparciu o drzewo decyzyjne na podstawie losowego podzbioru obserwacji oraz losowego zestawu atrybutów ze zbioru uczącego zwraca wytrenowanie na podanym zbiorze treningowym drzewo decyzyjne. Odsetek obserwacji oraz odsetek atrybutów wykorzystywanych do uczenia drzewa powinny zostać sparametryzowane. Zadbaj o powtarzalność otrzymywanych wyników. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_pred(X_data: pd.DataFrame, \n",
    "            y_data: pd.DataFrame,\n",
    "            params: dict,\n",
    "            seed: int=None):\n",
    "    \"\"\"\n",
    "    Funkcja 'dt_pred', która w oparciu o drzewo decyzyjne na podstawie losowego podzbioru obserwacji oraz losowego zestawu atrybutów ze zbioru uczącego zwraca \n",
    "    wytrenowane na podanym zbiorze treningowym drzewo decyzyjne.\n",
    "    Parameters:\n",
    "        X_data: pd.DataFrame <- dane wejściowe do modelowania\n",
    "        y_data: pd.DataFrame <- dane oczekiwane do modelowania\n",
    "        params: dict  <- słownik parametrów (plik 'params.yaml')\n",
    "        seed: int=None <- ziarno\n",
    "    Return:\n",
    "        modelTree <- wyuczone drzewo decyzyjne\n",
    "        feature_col <- lista cech wykorzystanych podczas trenowania drzewa decyzyjnego\n",
    "    \"\"\"\n",
    "    # Security\n",
    "    if params['Bagging_atribute']['pct_of_training_samples'] < 0 or params['Bagging_atribute']['pct_of_training_samples'] > 1:\n",
    "        raise ValueError(\"Feature `pct_of_training_samples` must have a value between 0 and 1.\")\n",
    "    if params['Bagging_atribute']['pct_of_features'] < 0 or params['Bagging_atribute']['pct_of_features'] > 1:\n",
    "        raise ValueError(\"Feature `num_of_features` must have a value between 0 and 1 (these are the percentages).\")\n",
    "    # Data preparation\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    else:\n",
    "        np.random.seed(params['seed'])\n",
    "    feature_col = np.random.choice(X_data.columns.values, \n",
    "                        round(params['Bagging_atribute']['pct_of_features']*len(X_data.columns.values)), \n",
    "                        replace=False)\n",
    "    X_data = X_data[feature_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,  \n",
    "                                                        y_data, \n",
    "                                                        train_size=params['Bagging_atribute']['pct_of_training_samples'], \n",
    "                                                        random_state=params['seed'],\n",
    "                                                        )\n",
    "    # Train model\n",
    "    modelTree = DecisionTreeRegressor(criterion=params['DecisionTree']['criterion'], \n",
    "                                      max_depth=params['DecisionTree']['max_depth'],\n",
    "                                      min_samples_split=params['DecisionTree']['min_samples_split'],\n",
    "                                      random_state=seed)\n",
    "    modelTree.fit(X_train, y_train)\n",
    "    return modelTree, feature_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "Następnie skonstruuj funkcję 'dt_bagg', która wykorzystywać będzie funkcję 'dt_pred' (jako tzw. weak learner) w procedurze baggingu*. Pamiętaj o uwzględnieniu odpowiednich (hiper)parametrów tej funkcji. Jeżeli to możliwe postaraj się zrównoleglić obliczenia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dt_bagg:\n",
    "    def __init__(self,\n",
    "                params: dict):\n",
    "        \"\"\"\n",
    "        Klasa 'dt_bagg' została zaprojektowana jako algotyrm zespołowy (ensemble algorithm), który dopasowuje wiele modeli drzew decyzyjnych \n",
    "        do różnych podzbiorów danych treningowych, a następnie łączy przewidywania wszystkich modeli. Klasa przyjmuej jeden parametr: \n",
    "            params <- słownik parametrów (plik 'params.yaml') \n",
    "        Klasa zawiera 2 funkcje: \n",
    "            fit(X_train: pd.DataFrame, y_train: pd.DataFrame) <- wytrenowanie modelu\n",
    "            predict(X_test: pd.DataFrame) <- predykcja wartości ciągłych dla danych testowych\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        # Security\n",
    "        if(self.params['RandomForest']['n_trees'] < 1):\n",
    "            raise ValueError(f\"Feature `n_trees` must have a integer greater or equal 1.\")\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.DataFrame):\n",
    "        np.random.seed(self.params['seed'])\n",
    "        list_of_seed = np.random.randint(0,10000, int(self.params['RandomForest']['n_trees']))\n",
    "        self.trainedTree = [dt_pred(X_train, y_train, self.params, dt_random_state) for dt_random_state in list_of_seed]\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame):\n",
    "        y_pred = np.mean([self.trainedTree[idx][0].predict(X_test[self.trainedTree[idx][1]]) for idx in range(len(self.trainedTree))], axis=0)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Zadanie 3\n",
    "Wykorzystaj napisaną przez siebie funkcję 'dt_bagg', aby na podstawie danych z załączonych plików (pliki 'signal.csv', 'time.csv' oraz 'descriptive.csv') zbudować odpowiednie modele prognozujące zmienną 'y' za pomocą zmiennych 'x_1'-'x_78'. Dokonaj podziału na zbiór treningowy oraz zbiór testowy losując 150 obserwacji.\n",
    "Porównaj jakość otrzymanych prognoz w oparciu o: \n",
    "<ul>\n",
    "  <li>Wykorzystanie funkcji 'dt_bagg' która zbuduje 100 niezależnych drzew, gdzie każde indywidualne drzewo uczone będzie na 80% obserwacji ze zbioru treningowego oraz 80% dostępnych atrybutów </li>\n",
    "  <li>Wykorzystanie funkcji 'dt_bagg' która zbuduje 200 niezależnych drzew, gdzie każde indywidualne drzewo uczone będzie na 70% obserwacji ze zbioru treningowego oraz 50% dostępnych atrybutów </li>\n",
    "</ul>\n",
    "Oceń i porównaj na zbiorze testowym jakość prognoz otrzymanych za pomocą obu podejść.\n",
    "Czy dobór (hiper)parametrów ma wpływ na otrzymywane wyniki? Czy jesteś w stanie zaproponować inny (lepszy) dobór tych parametrów?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset: dict, params: dict):\n",
    "    \"\"\"\n",
    "    Funkcja do trenowania modeli na wyznaczonym zbiorze danych oraz o określionych hiperparametrach. Całość przygotowana pod MLflow Tracking.\n",
    "    Parameters:\n",
    "        dataset: dict <- słownik z danymi treningowymi i tesowymi\n",
    "        params: dict <- słownik parametrów (plik 'params.yaml') \n",
    "    Return:\n",
    "        output <- wyniki eksperymentu zapisane w folderze 'mlruns/0'. W celu zobaczenia oraz porówania przeprowadzonych eksperymentów w konsole \n",
    "            należy wpisać \"$ mlflow ui\" oraz przejść do okna przeglądarki po yrl: 'http://localhost:5000'\n",
    "    \"\"\"\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        if params['type_model'] == 'dt_bagg':\n",
    "            reg_model = dt_bagg(params=params)\n",
    "            reg_model.fit(dataset[\"train\"][\"X\"], dataset[\"train\"][\"y\"])\n",
    "            y_pred_train = reg_model.predict(dataset[\"train\"][\"X\"])\n",
    "            y_pred_test = reg_model.predict(dataset[\"test\"][\"X\"])\n",
    "        elif params['type_model'] == 'BaggingRegression':\n",
    "            reg_model = BaggingRegressor(\n",
    "                base_estimator=DecisionTreeRegressor(\n",
    "                    criterion=params['DecisionTree']['criterion'], \n",
    "                    max_depth=params['DecisionTree']['max_depth'],\n",
    "                    min_samples_split=params['DecisionTree']['min_samples_split'],\n",
    "                    random_state=params['seed']), \n",
    "                n_estimators=params['RandomForest']['n_trees'], \n",
    "                max_samples=params['Bagging_atribute']['pct_of_training_samples'], \n",
    "                max_features=params['Bagging_atribute']['pct_of_features'],\n",
    "                bootstrap=False,\n",
    "                oob_score=False,\n",
    "                n_jobs=-1,\n",
    "                random_state=params['seed']\n",
    "            )\n",
    "            reg_model.fit(dataset[\"train\"][\"X\"], dataset[\"train\"][\"y\"])\n",
    "            y_pred_train = reg_model.predict(dataset[\"train\"][\"X\"])\n",
    "            y_pred_test = reg_model.predict(dataset[\"test\"][\"X\"])\n",
    "\n",
    "        rmse_train, mae_train, r2_train = eval_metrics(dataset['train']['y'], y_pred_train)\n",
    "        rmse_test, mae_test, r2_test = eval_metrics(dataset['test']['y'], y_pred_test)\n",
    "\n",
    "        mlflow.set_tag('mlflow.source.name', \"-\")\n",
    "        mlflow.log_param(\"Type_model\", params[\"type_model\"])\n",
    "        mlflow.log_param(\"criterion\", params[\"DecisionTree\"]['criterion'])\n",
    "        mlflow.log_param(\"max_depth\", params[\"DecisionTree\"]['max_depth'])\n",
    "        mlflow.log_param(\"min_samples_split\", params[\"DecisionTree\"]['min_samples_split'])\n",
    "        mlflow.log_param(\"n_trees\", params[\"RandomForest\"]['n_trees'])\n",
    "        mlflow.log_param(\"pct_of_features\", params[\"Bagging_atribute\"]['pct_of_features'])\n",
    "        mlflow.log_param(\"pct_of_training_samples\", params[\"Bagging_atribute\"]['pct_of_training_samples'])\n",
    "        mlflow.log_param(\"seed\", params[\"seed\"])\n",
    "\n",
    "        mlflow.log_metric(\"train_RMSE\", rmse_train)\n",
    "        mlflow.log_metric(\"train_MAE\",  mae_train)\n",
    "        mlflow.log_metric(\"train_R2\", r2_train)\n",
    "        mlflow.log_metric(\"test_RMSE\", rmse_test)\n",
    "        mlflow.log_metric(\"test_MAE\",  mae_test)\n",
    "        mlflow.log_metric(\"test_R2\", r2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params.yaml\", \"r\") as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "df_descriptive = pd.read_json('data/descriptive_v2.json')\n",
    "main_dataset_dict = preperation_data(df_descriptive, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 \n",
    "length = 2*3*5*3*2\n",
    "for type_model in ['dt_bagg', 'BaggingRegression']:\n",
    "    for criterion in ['squared_error', 'friedman_mse', 'absolute_error']:\n",
    "        for max_depth in [4, 6, 8, 10, None]:\n",
    "            for min_samples_split in [2, 3, 4]:\n",
    "                for n_trees, pct_of_features, pct_of_training_samples in zip([100, 200], [0.8, 0.5], [0.8, 0.7]):\n",
    "                    idx+=1\n",
    "                    params['type_model'] = type_model\n",
    "                    params['DecisionTree']['criterion'] = criterion\n",
    "                    params['DecisionTree']['max_depth'] = max_depth\n",
    "                    params['DecisionTree']['min_samples_split'] = min_samples_split\n",
    "                    params['RandomForest']['n_trees'] = n_trees\n",
    "                    params['Bagging_atribute']['pct_of_training_samples'] = pct_of_training_samples\n",
    "                    params['Bagging_atribute']['pct_of_features'] = pct_of_features\n",
    "                    print(f'Training model loading: {idx}/{length}')\n",
    "                    train_model(dataset=main_dataset_dict,\n",
    "                        params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ocena otrzymanych eksperymentów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku tego zadania mamy do czynienia z problemem regresyjnym, a więc do porównywania jakości modeli wykorzytamy 3 miary jakości: $MAE$, $RMSE$, $R2$. Badane modele były testowane na następujących hiperparametrach:\n",
    "- `criterion: ['squared_error', 'friedman_mse', 'absolute_error']` - funkcje do mierzenia jakości podziału;\n",
    "- `max_depth: [4, 6, 8, 10, None]` - maksymalna głębokość drzewa\n",
    "- `min_samples_split: [2, 3, 4]` - minimalna liczba próbek wymagana do podziału węzła\n",
    "\n",
    "Dodatkowo w zadaniu oparłem się o model BaggingRegression, w celu porówaniania jakości otrzymanej regresji z modelem zaimplementowanym w bibliotece `sklearn`.\n",
    "\n",
    "Wnioski:\n",
    "1. Otrzymywane wyniki dochodzą do poziomu 0.27 $R^2$ na zbiorze testowym. Jednakże czasami zdarzają nam się obserwacje bliskie zera. Generalnie takie wyniki świadczą o tym, że nasza zmienna zależna (predykowana) jest ciężko wyjaśnialna przez nasze zmienne. \n",
    "2. W przygotowanym doświadczeniu dużo częściej lepiej poradziły sobie modele złożone ze 100 drzew decyzyjnych o wysokiej zawartości danych (80%/80%) niż te skłądające z większej liczby drzew decyzyjnych, ale słabszej reprezentacji danych (70%/50%). Przyczyną takiego stanu rzeczy może być fakt, że dużo cech było ze sobą silnie skorelowanych. Jeśli w ramach wyboru 50% wszystkich cech trafimy na zbiór składający się głównie z danych skorelowanych to jakość niesionej informacji jest bardzo niska. A to skutkuje otrzymaniem słabego modelu. Większa ilość drzew byłaby skudeczna, jeśli dane byłoby w duże części niezależne od siebie.\n",
    "3. Dużą wadą otrzymanych modeli jest fakt, że dochodzi do przeuczenia. Dopasowanie $R^2$ na poziomie 0.9 na zbiorze treningowym oraz 0.2 na zbiorze testowym świadczy o tym, że albo mamy za mało danych albo wykorzystywany model jest za słaby dla tego zadania.\n",
    "4. Dobór odpowiednich hiperparametrów modelu jest często cechą indywidualną dla danego zbioru danych, co zmusza nas często do poszukiwania odpowiednich hiperparametrów w ich pełmym zakresie. \n",
    "5. Model BaggingRegression poradził sobie w tym zadaniu trochę lepiej (0.309 $R^2$) niż zaimplementowana przeze mnie funkcja dt_bagg z głównego powodu, hiperparametr `max_feature` odpowiada maksymalnemu procentowi udział cech w procesie uczenia, czyli jeśli zajdzie taka potrzeba to model może do uczenia modelu może wykorzystać znacznie mniejsza ilość cech, gdzie w przypadku dt_bagg mamy sztywno określoną liczbę cech. Taka sama sytuacja występuje przy hiperparametrze `max_samples`.\n",
    "6. Zaproponowanie dodatkowych hiperparametrów dla już istniejących funkcji nie zmieni znacznie otrzymywanych wyników. Chcąc poprawić jakość naszych predykcji należałoby zastanowić się:\n",
    "- czy nie lepiej jest wybrać inną architekturę modelu (np. na zespoły pionowe tzw. modele boostingowe)?\n",
    "- czy nie należałoby zwiększyć ilości danych (zarówno o nowe rekordy jak również nowe cechy)? np. rozbudować bazę w oparciu o szeregi czasowy\n",
    "- w jaki sposób lepiej by było przeprowadzić naprawę naszych danych?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv_3Soft': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c3a066d0aa5fddb223fa2e7d01ee0131b124deabffdfb60f1ea4a02c03483ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
